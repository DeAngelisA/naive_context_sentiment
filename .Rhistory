, all.x = TRUE)
text.valence_shifters = text.valence_shifters[order(index),]
text.table = text.valence_shifters
#recode valence shifters
names(text.table)[3:4] = c('sentiment'
, 'valence_shifter')
#define context cluster
sentiment_indices = text.table$index[!is.na(text.table$sentiment)]
text.table$context_cluster = ifelse(!is.na(text.table$sentiment), text.table$index, NA)
text.table$context_cluster = sapply(text.table$context_cluster, function(x){
transformed_col = ifelse(x %in% sentiment_indices
, which(x == sentiment_indices)
, text.table$context_cluster
)
})
text.table %>%
mutate(context_cluster_i = coalesce(context_cluster
, lead(context_cluster, 1)
, lead(context_cluster, 2)
, lead(context_cluster, 3)
, lead(context_cluster, 4)
, lag(context_cluster)
, lag(context_cluster, 2)
)
)
text.table
mutate(context_cluster_i = coalesce(context_cluster
, lead(context_cluster, 1)
, lead(context_cluster, 2)
, lead(context_cluster, 3)
, lead(context_cluster, 4)
, lag(context_cluster)
, lag(context_cluster, 2)
)
)
text.table %>%
mutate(context_cluster_i = coalesce(context_cluster
, lead(context_cluster, 1)
, lead(context_cluster, 2)
, lead(context_cluster, 3)
, lead(context_cluster, 4)
, lag(context_cluster)
, lag(context_cluster, 2)
)
)
mutate(text.table, context_cluster_i = coalesce(context_cluster
, lead(context_cluster, 1)
, lead(context_cluster, 2)
, lead(context_cluster, 3)
, lead(context_cluster, 4)
, lag(context_cluster)
, lag(context_cluster, 2)
)
)
text.table
text.table =  mutate(text.table, context_cluster_i = coalesce(context_cluster
, lead(context_cluster, 1)
, lead(context_cluster, 2)
, lead(context_cluster, 3)
, lead(context_cluster, 4)
, lag(context_cluster)
, lag(context_cluster, 2)
)
)
text.table
#find the index
a = text.table$context_cluster[1:8]
a
coalesce(a
, lead(a, 1)
, lead(a, 2)
, lag(a)
)
temp_list = sapply(text.table$index, function(i){
if(!is.na(text.table$context_cluster[i])){
target_index_start = i - 2
target_index_end = i + 2
mini_context_iter = text.table$context_cluster[target_index_start:target_index_end]
} else {
NULL
}
})
temp_list
ll = list()
ll = list()
temp_list = sapply(text.table$index, function(i){
if(!is.na(text.table$context_cluster[i])){
target_index_start = i - 2
target_index_end = i + 2
ll[[i]][1] = text.table[target_index_start:target_index_end, ]
} else {
NULL
}
})
temp_list = sapply(text.table$index, function(i){
if(!is.na(text.table$context_cluster[i])){
target_index_start = i - 2
target_index_end = i + 2
xxx = text.table[target_index_start:target_index_end, ]
} else {
NULL
}
})
temp_list
text.sentiment = merge(text.raw
, hash.sentiment
, by.x = 'text'
, by.y = 'x'
, all.x = TRUE)
text.sentiment = text.sentiment[order(index),]
#locate valence shifters
text.valence_shifters = merge(text.sentiment
, hash.valence_shifters
, by.x = 'text'
, by.y = 'x'
, all.x = TRUE)
text.valence_shifters = text.valence_shifters[order(index),]
text.table = text.valence_shifters
#recode valence shifters
names(text.table)[3:4] = c('sentiment'
, 'valence_shifter')
#define context cluster
sentiment_indices = text.table$index[!is.na(text.table$sentiment)]
text.table$context_cluster = ifelse(!is.na(text.table$sentiment), text.table$index, NA)
text.table$context_cluster = sapply(text.table$context_cluster, function(x){
transformed_col = ifelse(x %in% sentiment_indices
, which(x == sentiment_indices)
, text.table$context_cluster
)
})
# text.table =  mutate(text.table, context_cluster_i = coalesce(context_cluster
#                                     , lead(context_cluster, 1)
#                                     , lead(context_cluster, 2)
#                                     , lead(context_cluster, 3)
#                                     , lead(context_cluster, 4)
#                                     , lag(context_cluster)
#                                     , lag(context_cluster, 2)
#                                     )
#                      )
context_list = sapply(text.table$index, function(i){
if(!is.na(text.table$context_cluster[i])){
target_index_start = i - 2
target_index_end = i + 2
xxx = text.table[target_index_start:target_index_end, ]
} else {
NULL
}
})
cluster_lead = 4
custer_lag = 2
cluster_lead = 4
custer_lag = 2
context_list = sapply(text.table$index, function(i){
if(!is.na(text.table$context_cluster[i])){
if(i - cluster_lead <= 0){
target_index_start = 0
} else {
target_index_start = i - cluster_lead
}
if(i + cluster_lag > max(text.table$index)){
target_index_end = max(text.table$index)
} else {
target_index_end = i + cluster_lag
}
mini_context_iter = text.table[target_index_start:target_index_end, ]
} else {
NULL
}
})
cluster_lead = 4
cluster_lag = 2
context_list = sapply(text.table$index, function(i){
if(!is.na(text.table$context_cluster[i])){
if(i - cluster_lead <= 0){
target_index_start = 0
} else {
target_index_start = i - cluster_lead
}
if(i + cluster_lag > max(text.table$index)){
target_index_end = max(text.table$index)
} else {
target_index_end = i + cluster_lag
}
mini_context_iter = text.table[target_index_start:target_index_end, ]
} else {
NULL
}
})
context_list
context_list = Filter(Negate(is.null), context_list)
context_list
-1*-1
-1^3
-1^2
(-1)^2
?sentiment
hash.valence_shifters
View(hash.valence_shifters)
sentiment
###############################################################################
##### NARRATIVE STRUCTURE OF VLOGS ON YOUTUBE
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
###############################################################################
### ANALYSIS
### FOR PREPROCESSING SEE narr_structure_1.R
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(tm)
require(data.table)
require(tidyr)
require(syuzhet)
require(tidyverse)
require(cluster)
require(factoextra)
require(parallel)
require(rlist)
require(quanteda)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./get_narrative_dim.R')
source('./ncs.full.R')
setwd('/Users/bennettkleinberg/GitHub/naive_context_sentiment')
source('./ncs.full.R')
setwd('/Users/bennettkleinberg/Documents/Research/UCL/narrative_structures_local/data/output_dir')
#START ANALYSIS
load('vlogs_data_07032018.RData')
rm(df.full_corpus, df.meta)
###############################################################################
##### NARRATIVE STRUCTURE OF VLOGS ON YOUTUBE
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(tm)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
require(data.table)
###############################################################################
##### NARRATIVE STRUCTURE OF VLOGS ON YOUTUBE
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(tm)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
require(data.table)
## set dir
setwd('/Users/bennettkleinberg/GitHub/narrative_structures/data/output_dir/parsed')
###############################################################################
##### NARRATIVE STRUCTURE OF VLOGS ON YOUTUBE
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(tm)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
require(data.table)
## set dir
setwd('/Users/bennettkleinberg/GitHub/narrative_structures/data/output_dir/parsed')
#LOAD DATA
## read raw data
t1 = Sys.time()
df.full_corpus = txt_df_from_dir(dirpath = './'
, recursive = T
, include_processed = T)
###############################################################################
##### NARRATIVE STRUCTURE OF VLOGS ON YOUTUBE
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(tm)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
require(data.table)
## set dir
setwd('/Users/bennettkleinberg/GitHub/narrative_structures/data/output_dir/parsed')
#LOAD DATA
## read raw data
t1 = Sys.time()
df.full_corpus = txt_df_from_dir(dirpath = './'
, recursive = T
, include_processed = F)
t2 = Sys.time()
t2-t1
dim(df.full_corpus)
sub('(.*)\\..*','\\1', df.full_corpus$file_id)
## set variable for merge with meta data
df.full_corpus$vlog_id = sub('(.*)\\..*','\\1', df.full_corpus$file_id)
paste(df.full_corpus$file_parent, df.full_corpus$vlog_id, sep="_")
df.full_corpus$channel_vlog_id = paste(df.full_corpus$file_parent, df.full_corpus$vlog_id, sep="_")
df.full_corpus = df.full_corpus[nchar(df.full_corpus$text) > 0, ]
df.full_corpus = droplevels(df.full_corpus)
df.meta = as.data.frame(fread('../../overview.txt'
, sep = ","
, header=F))
names(df.meta)
head(df.meta)
names(df.meta) = c('channel_id'
, 'file_id'
, 'url'
, 'view_count'
, 'date_posted'
, 'landing_url')
sub('(.*)\\..*','\\1', df.meta$channel_id)
df.meta$channel_id = sub('(.*)\\..*','\\1', df.meta$channel_id)
paste(df.meta$channel_id, df.meta$file_id, sep="_")
df.meta$channel_vlog_id = paste(df.meta$channel_id, df.meta$file_id, sep="_")
as.numeric(gsub("[.]", "", as.character(df.meta$view_count)))
df.meta$view_count = as.numeric(gsub("[.]", "", as.character(df.meta$view_count)))
df.meta$date_posted = as.Date(df.meta$date_posted)
reference_date = as.Date('2018-04-09')
df.meta$days_until_reference = as.numeric(reference_date - df.meta$date_posted)
df.meta$days_until_reference
df.meta$view_count_corrected = round(df.meta$view_count/df.meta$days_until_reference, 2)
## merge
df.data = merge(df.full_corpus, df.meta, by='channel_vlog_id')
dim(df.data)
dim(df.full_corpus)
dim(df.meta)
table(df.full_corpus$channel_vlog_id)
table(df.meta$channel_vlog_id)
!(df.full_corpus$channel_vlog_id %in% df.meta$channel_vlog_id)
df.full_corpus$channel_vlog_id[!(df.full_corpus$channel_vlog_id %in% df.meta$channel_vlog_id)]
df.full_corpus$vlog_id = sub('(.*)\\..*','\\1', df.full_corpus$file_id)
df.full_corpus$channel_vlog_id = tolower(paste(df.full_corpus$file_parent, df.full_corpus$vlog_id, sep="_"))
df.full_corpus = df.full_corpus[nchar(df.full_corpus$text) > 0, ]
df.full_corpus = droplevels(df.full_corpus)
df.meta = as.data.frame(fread('../../overview.txt'
, sep = ","
, header=F))
names(df.meta) = c('channel_id'
, 'file_id'
, 'url'
, 'view_count'
, 'date_posted'
, 'landing_url')
df.meta$channel_id = sub('(.*)\\..*','\\1', df.meta$channel_id)
df.meta$channel_vlog_id = tolower(paste(df.meta$channel_id, df.meta$file_id, sep="_"))
df.meta$view_count = as.numeric(gsub("[.]", "", as.character(df.meta$view_count)))
df.meta$date_posted = as.Date(df.meta$date_posted)
reference_date = as.Date('2018-04-09')
df.meta$days_until_reference = as.numeric(reference_date - df.meta$date_posted)
df.meta$view_count_corrected = round(df.meta$view_count/df.meta$days_until_reference, 2)
## merge
df.data = merge(df.full_corpus, df.meta, by='channel_vlog_id')
dim(df.data)
dim(df.full_corpus)
## merge
df.data = merge(df.full_corpus, df.meta, by='channel_vlog_id', all=T)
dim(df.data)
## merge
df.data = merge(df.full_corpus, df.meta, by='channel_vlog_id', all.x = T)
dim(df.data)
## merge
dim(df.full_corpus)
dim(df.meta)
###############################################################################
##### NARRATIVE STRUCTURE OF VLOGS ON YOUTUBE
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(tm)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
require(data.table)
## set dir
setwd('/Users/bennettkleinberg/GitHub/narrative_structures/data/output_dir/parsed')
#LOAD DATA
## read raw data
t1 = Sys.time()
df.full_corpus = txt_df_from_dir(dirpath = './'
, recursive = T
, include_processed = F)
t2 = Sys.time()
t2-t1
df.full_corpus$vlog_id = sub('(.*)\\..*','\\1', df.full_corpus$file_id)
df.full_corpus$channel_vlog_id = tolower(paste(df.full_corpus$file_parent, df.full_corpus$vlog_id, sep="_"))
df.full_corpus = df.full_corpus[nchar(df.full_corpus$text) > 0, ]
df.full_corpus = droplevels(df.full_corpus)
nrow(df.full_corpus)
df.meta = as.data.frame(fread('../../overview.txt'
, sep = ","
, header=F))
names(df.meta) = c('channel_id'
, 'file_id'
, 'url'
, 'view_count'
, 'date_posted'
, 'landing_url')
df.meta$channel_id = sub('(.*)\\..*','\\1', df.meta$channel_id)
df.meta$channel_vlog_id = tolower(paste(df.meta$channel_id, df.meta$file_id, sep="_"))
df.meta$view_count = as.numeric(gsub("[.]", "", as.character(df.meta$view_count)))
df.meta$date_posted = as.Date(df.meta$date_posted)
reference_date = as.Date('2018-04-09')
df.meta$days_until_reference = as.numeric(reference_date - df.meta$date_posted)
df.meta$view_count_corrected = round(df.meta$view_count/df.meta$days_until_reference, 2)
## merge
dim(df.full_corpus)
dim(df.meta)
df.data = merge(df.full_corpus, df.meta, by='channel_vlog_id')
dim(df.data)
df.data = merge(df.full_corpus, df.meta, by='channel_vlog_id', all = T)
dim(df.data)
df.data = merge(df.full_corpus, df.meta, by='channel_vlog_id')
dim(df.data)
table(is.na(df.data))
which(is.na(df.data))
View(df.data[which(is.na(df.data)), ])
df.data = na.omit(df.data)
dim(df.data)
duplicated(df.data)
table(duplicated(df.data))
save(df.data
, df.meta
, df.full_corpus
, file='vlogs_data_27042018.RData')
setwd('/Users/bennettkleinberg/GitHub/naive_context_sentiment')
source('./ncs.full.R')
a = ncs.full(txt_input_col = df.full_corpus$text[1:10]
, txt_id_col = df.full_corpus$text_id[1:10]
, transform_values = T
)
a = ncs.full(txt_input_col = df.full_corpus$text[1:10]
, txt_id_col = df.full_corpus$channel_vlog_id[1:10]
, transform_values = T
)
a
a = ncs.full(txt_input_col = df.full_corpus$text[1:10]
, txt_id_col = df.full_corpus$channel_vlog_id[1:10]
, transform_values = F
)
a
strsplit(df.full_corpus$text[1:10])
strsplit(df.full_corpus$text[1:10], ' ')
str_replace_all(df.full_corpus$text[10], "[\n]", "")
df.full_corpus$text[10]
str_replace_all(df.full_corpus$text[10], "[\n]", " ")
str_replace_all(df.full_corpus$text[10], "[\n]", "")
length(unlist(str_split(df.full_corpus$text[1:10], ' ')))
length(str_split(df.full_corpus$text[1:10], ' '))
str_split(df.full_corpus$text[1:10], ' ')
lapply(str_split(df.full_corpus$text[1:10], ' '), length)
unlist(lapply(str_split(df.full_corpus$text[1:10], ' '), length))
###############################################################################
##### NARRATIVE STRUCTURE OF VLOGS ON YOUTUBE
##### KLEINBERG, MOZES, VAN DER VEGT ###
###############################################################################
# PREPARATION
## clear ws
rm(list = ls())
## load deps
require(tm)
setwd('/Users/bennettkleinberg/GitHub/r_helper_functions')
source('./txt_df_from_dir.R')
require(data.table)
## set dir
setwd('/Users/bennettkleinberg/GitHub/narrative_structures/data/output_dir/parsed')
#LOAD DATA
## read raw data
t1 = Sys.time()
df.full_corpus = txt_df_from_dir(dirpath = './'
, recursive = T
, include_processed = F)
t2 = Sys.time()
t2-t1
summary(df.full_corpus$nwords)
## set variable for merge with meta data
df.full_corpus$vlog_id = sub('(.*)\\..*','\\1', df.full_corpus$file_id)
df.full_corpus$channel_vlog_id = tolower(paste(df.full_corpus$file_parent, df.full_corpus$vlog_id, sep="_"))
df.full_corpus = df.full_corpus[nchar(df.full_corpus$text) > 0, ]
df.full_corpus = droplevels(df.full_corpus)
setwd('/Users/bennettkleinberg/GitHub/naive_context_sentiment')
source('./ncs.full.R')
a = ncs.full(txt_input_col = df.full_corpus$text[1:10]
, txt_id_col = df.full_corpus$channel_vlog_id[1:10]
, transform_values = F
)
setwd('/Users/bennettkleinberg/GitHub/naive_context_sentiment')
source('./ncs.full.R')
a = ncs.full(txt_input_col = df.full_corpus$text[1:10]
, txt_id_col = df.full_corpus$channel_vlog_id[1:10]
, transform_values = F
)
dim(a)
dim(t(a))
plot(a$`1jessalynn_100`
, type = 'h')
a = ncs.full(txt_input_col = df.full_corpus$text[1:10]
, txt_id_col = df.full_corpus$channel_vlog_id[1:10]
, transform_values = T
)
plot(a$`1jessalynn_100`
, type = 'h')
plot(a$`1jessalynn_100`
, type = 'l')
